{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE_iwdR5m6xH"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/028_pytorch_nn/pytorch_nn.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjhgRWO_m6xK"
      },
      "source": [
        "# Pytorch - Redes Neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVNrcQ_5m6xK"
      },
      "source": [
        "En el post [anterior](https://sensioai.com/blog/027_pytorch_intro) hicimos una introducción al framework de `redes neuronales` `Pytorch`. Hablamos de sus tres elementos fundamentales: el objeto `tensor` (similar al `array` de `NumPy`) `autograd` (que nos permite calcular derivadas de manera automáticas) y el soporte GPU. En este post vamos a entrar en detalle en la  funcionalidad que nos ofrece la librería para diseñar redes neuronales de manera flexible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:21:45.471625Z",
          "start_time": "2020-08-15T12:21:45.002765Z"
        },
        "id": "4hnzhQywm6xL"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "IqUKyQ9Nm6xM"
      },
      "source": [
        "## Modelos secuenciales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "MDSz2Mbsm6xM"
      },
      "source": [
        "La forma más sencilla de definir una `red neuronal` en `Pytorch` es utilizando la clase `Sequentail`. Esta clase nos permite definir una secuencia de capas, que se aplicarán de manera secuencial (las salidas de una capa serán la entrada de la siguiente). Ésto ya lo conocemos de posts anteriores, ya que es la forma ideal de definir un `Perceptrón Multicapa`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:21:45.486329Z",
          "start_time": "2020-08-15T12:21:45.472624Z"
        },
        "hidden": true,
        "id": "V5KEpUHVm6xN"
      },
      "outputs": [],
      "source": [
        "D_in, H, D_out = 54, 100, 7\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "# D_in, H1, H2, D_out = 784, 100, 50, 10\n",
        "# model = torch.nn.Sequential(\n",
        "#     torch.nn.Linear(D_in, H1),\n",
        "#     torch.nn.ReLU(),\n",
        "#     torch.nn.Linear(H1, H2),\n",
        "#     torch.nn.ReLU(),\n",
        "#     torch.nn.Linear(H2, D_out),\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "8Ea8TfSWm6xO"
      },
      "source": [
        "El modelo anterior es un `MLP` con 784 entradas, 100 neuronas en la capa oculta y 10 salidas. Podemos usar este modelo para hacer un clasificador de imágenes con el dataset MNIST. Pero primero, vamos a ver como podemos calcular las salidas del modelo a partir de unas entradas de ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:21:45.502329Z",
          "start_time": "2020-08-15T12:21:45.487329Z"
        },
        "hidden": true,
        "id": "WVB30MPem6xO",
        "outputId": "b3510c14-561b-45b6-f1d1-e15885c001a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([600, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "outputs = model(torch.randn(600, 54))\n",
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs[0][:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7mk9EVzLeBV",
        "outputId": "3bd5d671-a269-4a10-f51b-177488169adf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0340, -0.4522,  0.1037, -0.0883, -0.0435, -0.0978,  0.0092],\n",
            "       grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "I-J9Sa6Qm6xP"
      },
      "source": [
        "Como puedes ver, simplemente le pasamos los inputs al modelo (llamándolo como una función). En este caso, usamos un tensor con 64 vectores de 784 valores. Es importante remarcar que los modelos de `Pytorch` (por lo general) siempre esperan que la primera dimensión sea la dimensión *batch*. Si queremos entrenar esta red en una GPU, es tan sencillo como"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSs12izZ97se",
        "outputId": "94c3545d-cb4e-49a4-fcc0-83198fd19d89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=54, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:21:46.777020Z",
          "start_time": "2020-08-15T12:21:45.503329Z"
        },
        "hidden": true,
        "id": "VjtJxIM_m6xQ",
        "outputId": "73269787-fa71-4ced-e188-6551073bcdb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=54, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "ZxmpSqz6m6xQ"
      },
      "source": [
        "Vamos a ver ahora como entrenar este modelo con el dataset MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:05.622262Z",
          "start_time": "2020-08-15T12:21:46.778019Z"
        },
        "hidden": true,
        "id": "OmlXe8Gpm6xR",
        "outputId": "ead98127-c061-4b06-82cf-5e0c658e6219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(581012, 54) (581012,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import Bunch\n",
        "\n",
        "# Cargar dataset desde tu CSV\n",
        "df = pd.read_csv(\"/content/covtype.csv\")\n",
        "\n",
        "# Separar features y target\n",
        "X = df.drop(\"Cover_Type\", axis=1)\n",
        "Y = df[\"Cover_Type\"]\n",
        "\n",
        "# Crear un objeto tipo Bunch como el de fetch_openml\n",
        "covtype = Bunch(data=X, target=Y)\n",
        "\n",
        "# Ahora puedes usarlo igual que MNIST\n",
        "X, Y = covtype[\"data\"], covtype[\"target\"]\n",
        "\n",
        "print(X.shape, Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:05.761911Z",
          "start_time": "2020-08-15T12:22:05.624102Z"
        },
        "hidden": true,
        "id": "BzhE25udm6xR",
        "outputId": "bb7baa72-627b-47a5-ad84-5ec1b9613fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(464809, 54) (116203, 54) (464809,) (116203,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Pasar a numpy arrays\n",
        "x_2 = np.array(X, dtype=np.float32)\n",
        "y_2 = np.array(Y, dtype=np.int32)\n",
        "\n",
        "# Normalización (media=0, varianza=1)\n",
        "scaler = StandardScaler()\n",
        "x_2 = scaler.fit_transform(x_2)\n",
        "\n",
        "# Split 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x_2, y_2, test_size=0.2, random_state=42, stratify=y_2\n",
        ")\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:05.777964Z",
          "start_time": "2020-08-15T12:22:05.763102Z"
        },
        "hidden": true,
        "id": "pDJK07Jpm6xR"
      },
      "outputs": [],
      "source": [
        "# función de pérdida y derivada\n",
        "\n",
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "def cross_entropy(output, target):\n",
        "    logits = output[torch.arange(len(output)), target]\n",
        "    loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))\n",
        "    loss = loss.mean()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train"
      ],
      "metadata": {
        "id": "E0mXU4_t5c-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHL3LiGejvr0",
        "outputId": "816da919-a5c3-4deb-d777-fe6a6873c650"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "tZCJjxDZyenK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946c2ca3-a784-44c3-8ba0-c41dcd754a42"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
            "0            2596      51      3                               258   \n",
            "1            2590      56      2                               212   \n",
            "2            2804     139      9                               268   \n",
            "3            2785     155     18                               242   \n",
            "4            2595      45      2                               153   \n",
            "...           ...     ...    ...                               ...   \n",
            "581007       2396     153     20                                85   \n",
            "581008       2391     152     19                                67   \n",
            "581009       2386     159     17                                60   \n",
            "581010       2384     170     15                                60   \n",
            "581011       2383     165     13                                60   \n",
            "\n",
            "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
            "0                                    0                              510   \n",
            "1                                   -6                              390   \n",
            "2                                   65                             3180   \n",
            "3                                  118                             3090   \n",
            "4                                   -1                              391   \n",
            "...                                ...                              ...   \n",
            "581007                              17                              108   \n",
            "581008                              12                               95   \n",
            "581009                               7                               90   \n",
            "581010                               5                               90   \n",
            "581011                               4                               67   \n",
            "\n",
            "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
            "0                 221             232            148   \n",
            "1                 220             235            151   \n",
            "2                 234             238            135   \n",
            "3                 238             238            122   \n",
            "4                 220             234            150   \n",
            "...               ...             ...            ...   \n",
            "581007            240             237            118   \n",
            "581008            240             237            119   \n",
            "581009            236             241            130   \n",
            "581010            230             245            143   \n",
            "581011            231             244            141   \n",
            "\n",
            "        Horizontal_Distance_To_Fire_Points  ...  Soil_Type31  Soil_Type32  \\\n",
            "0                                     6279  ...            0            0   \n",
            "1                                     6225  ...            0            0   \n",
            "2                                     6121  ...            0            0   \n",
            "3                                     6211  ...            0            0   \n",
            "4                                     6172  ...            0            0   \n",
            "...                                    ...  ...          ...          ...   \n",
            "581007                                 837  ...            0            0   \n",
            "581008                                 845  ...            0            0   \n",
            "581009                                 854  ...            0            0   \n",
            "581010                                 864  ...            0            0   \n",
            "581011                                 875  ...            0            0   \n",
            "\n",
            "        Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
            "0                 0            0            0            0            0   \n",
            "1                 0            0            0            0            0   \n",
            "2                 0            0            0            0            0   \n",
            "3                 0            0            0            0            0   \n",
            "4                 0            0            0            0            0   \n",
            "...             ...          ...          ...          ...          ...   \n",
            "581007            0            0            0            0            0   \n",
            "581008            0            0            0            0            0   \n",
            "581009            0            0            0            0            0   \n",
            "581010            0            0            0            0            0   \n",
            "581011            0            0            0            0            0   \n",
            "\n",
            "        Soil_Type38  Soil_Type39  Soil_Type40  \n",
            "0                 0            0            0  \n",
            "1                 0            0            0  \n",
            "2                 0            0            0  \n",
            "3                 0            0            0  \n",
            "4                 0            0            0  \n",
            "...             ...          ...          ...  \n",
            "581007            0            0            0  \n",
            "581008            0            0            0  \n",
            "581009            0            0            0  \n",
            "581010            0            0            0  \n",
            "581011            0            0            0  \n",
            "\n",
            "[581012 rows x 54 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:07.268014Z",
          "start_time": "2020-08-15T12:22:05.778966Z"
        },
        "hidden": true,
        "id": "EjdhOJ90m6xS",
        "outputId": "de86079c-cf7b-4eef-d413-96e7a257fafa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/350 Loss nan\n",
            "Epoch 20/350 Loss nan\n",
            "Epoch 30/350 Loss nan\n",
            "Epoch 40/350 Loss nan\n",
            "Epoch 50/350 Loss nan\n",
            "Epoch 60/350 Loss nan\n",
            "Epoch 70/350 Loss nan\n",
            "Epoch 80/350 Loss nan\n",
            "Epoch 90/350 Loss nan\n",
            "Epoch 100/350 Loss nan\n",
            "Epoch 110/350 Loss nan\n",
            "Epoch 120/350 Loss nan\n",
            "Epoch 130/350 Loss nan\n",
            "Epoch 140/350 Loss nan\n",
            "Epoch 150/350 Loss nan\n",
            "Epoch 160/350 Loss nan\n",
            "Epoch 170/350 Loss nan\n",
            "Epoch 180/350 Loss nan\n",
            "Epoch 190/350 Loss nan\n",
            "Epoch 200/350 Loss nan\n",
            "Epoch 210/350 Loss nan\n",
            "Epoch 220/350 Loss nan\n",
            "Epoch 230/350 Loss nan\n",
            "Epoch 240/350 Loss nan\n",
            "Epoch 250/350 Loss nan\n",
            "Epoch 260/350 Loss nan\n",
            "Epoch 270/350 Loss nan\n",
            "Epoch 280/350 Loss nan\n",
            "Epoch 290/350 Loss nan\n",
            "Epoch 300/350 Loss nan\n",
            "Epoch 310/350 Loss nan\n",
            "Epoch 320/350 Loss nan\n",
            "Epoch 330/350 Loss nan\n",
            "Epoch 340/350 Loss nan\n",
            "Epoch 350/350 Loss nan\n"
          ]
        }
      ],
      "source": [
        "# convertimos datos a tensores y copiamos en gpu\n",
        "\n",
        "X_t = torch.from_numpy(X_train).float().cuda()\n",
        "Y_t = torch.from_numpy((y_train - 1).astype(np.int64)).long().cuda()\n",
        "\n",
        "# bucle entrenamiento\n",
        "epochs = 350\n",
        "lr = 0.8\n",
        "log_each = 10\n",
        "l = []\n",
        "for e in range(1, epochs + 1):\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(X_t)\n",
        "\n",
        "    # loss\n",
        "    loss = cross_entropy(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    # ponemos a cero los gradientes\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backprop (calculamos todos los gradientes automáticamente)\n",
        "    loss.backward()\n",
        "\n",
        "    # update de los pesos\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= lr * param.grad\n",
        "\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "5tCiIuSvm6xT"
      },
      "source": [
        "Como puedes observar en el ejemplo, podemos calcular la salida del modelo con una simple línea. Luego calculamos la función de pérdida, y llamando a la función `backward` `Pytorch` se encarga de calcular las derivadas de la misma con respecto a todos los parámetros del modelo automáticamente (si no queremos acumular estos gradientes, nos aseguramos de llamar a la función `zero_grad` para ponerlos a cero antes de calcularlos). Por útlimo, podemos iterar por los parámetros del modelo aplicando la regla de actualización deseada (en este caso usamos `descenso por gradiente`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:07.312014Z",
          "start_time": "2020-08-15T12:22:07.270016Z"
        },
        "hidden": true,
        "id": "Ufomq0IIm6xT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2c7e437-13cd-4fd4-ca42-f7150bcc17ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy en test: 0.3646\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate(x):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      y_pred = model(x)\n",
        "      y_probas = softmax(y_pred)\n",
        "    return torch.argmax(y_probas, axis=1)\n",
        "\n",
        "# Convertir X_test a tensor en GPU\n",
        "X_test_t = torch.from_numpy(X_test).float().cuda()\n",
        "\n",
        "# Corregir etiquetas (1–7 → 0–6)\n",
        "y_test_fixed = (y_test - 1).astype(np.int64)\n",
        "\n",
        "# Predicciones\n",
        "y_pred = evaluate(X_test_t)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test_fixed, y_pred.cpu().numpy())\n",
        "print(f\"Accuracy en test: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "lafBMelim6xT"
      },
      "source": [
        "Existen algunos tipos de capas que se comportan diferente en función de si estamos entrenando la red o usándola para generar predicciones. Podemos controlar el modo en el que queremos que esté nuestra red con las funciones `train` y `eval`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "bQJhUWy2m6xT"
      },
      "source": [
        "## Optimizadores y Funciones de pérdida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "wnj54ahUm6xU"
      },
      "source": [
        "En el ejemplo anterior hemos calculado la función de pérdida y aplicado la regla de optimización de forma manual. Sin embargo, `Pytorch` nos ofrece funcionalidad que nos abstrae estos cálculos ofreciendo además flexibilidad para aplicar diferentes funciones de pérdida o algoritmos de optimización de manera sencilla. Podemos encontrar diferentes funciones de pérdida ya implementadas en el paquete `torch.nn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:07.328014Z",
          "start_time": "2020-08-15T12:22:07.313014Z"
        },
        "hidden": true,
        "id": "8ZmyhLd5m6xU"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Yz70Aprzm6xU"
      },
      "source": [
        "Mientras que los optimizadores se encuentran en el paquete `torch.optim`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:07.343013Z",
          "start_time": "2020-08-15T12:22:07.330016Z"
        },
        "hidden": true,
        "id": "X8-BU1mbm6xU"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "GmOzqwGXm6xV"
      },
      "source": [
        "Puedes ver la lista completa de funciones de pérdida y optimizadores disponibles en la [documentación](https://pytorch.org/docs/stable/index.html), aunque como ya has visto siempre puedes definir los tuyos propios fácilmente.\n",
        "\n",
        "Una vez definidos estos dos objetos, nuestro bucle de entrenamiento se simplifica considerablemente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:08.626592Z",
          "start_time": "2020-08-15T12:22:07.344013Z"
        },
        "code_folding": [
          0
        ],
        "hidden": true,
        "id": "oz7CgSjum6xV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c3b19d-75f6-4396-d953-77cf9ab5522b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/1500 Loss 1.16789\n",
            "Epoch 20/1500 Loss 1.01057\n",
            "Epoch 30/1500 Loss 0.93038\n",
            "Epoch 40/1500 Loss 0.88197\n",
            "Epoch 50/1500 Loss 0.84722\n",
            "Epoch 60/1500 Loss 0.82145\n",
            "Epoch 70/1500 Loss 0.80136\n",
            "Epoch 80/1500 Loss 0.78505\n",
            "Epoch 90/1500 Loss 0.77150\n",
            "Epoch 100/1500 Loss 0.76002\n",
            "Epoch 110/1500 Loss 0.75010\n",
            "Epoch 120/1500 Loss 0.74140\n",
            "Epoch 130/1500 Loss 0.73367\n",
            "Epoch 140/1500 Loss 0.72673\n",
            "Epoch 150/1500 Loss 0.72046\n",
            "Epoch 160/1500 Loss 0.71475\n",
            "Epoch 170/1500 Loss 0.70951\n",
            "Epoch 180/1500 Loss 0.70468\n",
            "Epoch 190/1500 Loss 0.70020\n",
            "Epoch 200/1500 Loss 0.69604\n",
            "Epoch 210/1500 Loss 0.69216\n",
            "Epoch 220/1500 Loss 0.68851\n",
            "Epoch 230/1500 Loss 0.68508\n",
            "Epoch 240/1500 Loss 0.68184\n",
            "Epoch 250/1500 Loss 0.67877\n",
            "Epoch 260/1500 Loss 0.67586\n",
            "Epoch 270/1500 Loss 0.67308\n",
            "Epoch 280/1500 Loss 0.67044\n",
            "Epoch 290/1500 Loss 0.66791\n",
            "Epoch 300/1500 Loss 0.66549\n",
            "Epoch 310/1500 Loss 0.66317\n",
            "Epoch 320/1500 Loss 0.66094\n",
            "Epoch 330/1500 Loss 0.65880\n",
            "Epoch 340/1500 Loss 0.65674\n",
            "Epoch 350/1500 Loss 0.65476\n",
            "Epoch 360/1500 Loss 0.65286\n",
            "Epoch 370/1500 Loss 0.65101\n",
            "Epoch 380/1500 Loss 0.64923\n",
            "Epoch 390/1500 Loss 0.64751\n",
            "Epoch 400/1500 Loss 0.64585\n",
            "Epoch 410/1500 Loss 0.64424\n",
            "Epoch 420/1500 Loss 0.64267\n",
            "Epoch 430/1500 Loss 0.64116\n",
            "Epoch 440/1500 Loss 0.63970\n",
            "Epoch 450/1500 Loss 0.63827\n",
            "Epoch 460/1500 Loss 0.63689\n",
            "Epoch 470/1500 Loss 0.63554\n",
            "Epoch 480/1500 Loss 0.63422\n",
            "Epoch 490/1500 Loss 0.63294\n",
            "Epoch 500/1500 Loss 0.63169\n",
            "Epoch 510/1500 Loss 0.63047\n",
            "Epoch 520/1500 Loss 0.62928\n",
            "Epoch 530/1500 Loss 0.62811\n",
            "Epoch 540/1500 Loss 0.62697\n",
            "Epoch 550/1500 Loss 0.62585\n",
            "Epoch 560/1500 Loss 0.62476\n",
            "Epoch 570/1500 Loss 0.62369\n",
            "Epoch 580/1500 Loss 0.62264\n",
            "Epoch 590/1500 Loss 0.62162\n",
            "Epoch 600/1500 Loss 0.62061\n",
            "Epoch 610/1500 Loss 0.61962\n",
            "Epoch 620/1500 Loss 0.61866\n",
            "Epoch 630/1500 Loss 0.61771\n",
            "Epoch 640/1500 Loss 0.61678\n",
            "Epoch 650/1500 Loss 0.61586\n",
            "Epoch 660/1500 Loss 0.61496\n",
            "Epoch 670/1500 Loss 0.61408\n",
            "Epoch 680/1500 Loss 0.61321\n",
            "Epoch 690/1500 Loss 0.61236\n",
            "Epoch 700/1500 Loss 0.61152\n",
            "Epoch 710/1500 Loss 0.61070\n",
            "Epoch 720/1500 Loss 0.60988\n",
            "Epoch 730/1500 Loss 0.60908\n",
            "Epoch 740/1500 Loss 0.60829\n",
            "Epoch 750/1500 Loss 0.60752\n",
            "Epoch 760/1500 Loss 0.60675\n",
            "Epoch 770/1500 Loss 0.60600\n",
            "Epoch 780/1500 Loss 0.60525\n",
            "Epoch 790/1500 Loss 0.60453\n",
            "Epoch 800/1500 Loss 0.60381\n",
            "Epoch 810/1500 Loss 0.60310\n",
            "Epoch 820/1500 Loss 0.60240\n",
            "Epoch 830/1500 Loss 0.60172\n",
            "Epoch 840/1500 Loss 0.60104\n",
            "Epoch 850/1500 Loss 0.60037\n",
            "Epoch 860/1500 Loss 0.59972\n",
            "Epoch 870/1500 Loss 0.59907\n",
            "Epoch 880/1500 Loss 0.59843\n",
            "Epoch 890/1500 Loss 0.59779\n",
            "Epoch 900/1500 Loss 0.59717\n",
            "Epoch 910/1500 Loss 0.59655\n",
            "Epoch 920/1500 Loss 0.59595\n",
            "Epoch 930/1500 Loss 0.59535\n",
            "Epoch 940/1500 Loss 0.59475\n",
            "Epoch 950/1500 Loss 0.59417\n",
            "Epoch 960/1500 Loss 0.59359\n",
            "Epoch 970/1500 Loss 0.59301\n",
            "Epoch 980/1500 Loss 0.59245\n",
            "Epoch 990/1500 Loss 0.59189\n",
            "Epoch 1000/1500 Loss 0.59133\n",
            "Epoch 1010/1500 Loss 0.59079\n",
            "Epoch 1020/1500 Loss 0.59024\n",
            "Epoch 1030/1500 Loss 0.58971\n",
            "Epoch 1040/1500 Loss 0.58918\n",
            "Epoch 1050/1500 Loss 0.58865\n",
            "Epoch 1060/1500 Loss 0.58813\n",
            "Epoch 1070/1500 Loss 0.58762\n",
            "Epoch 1080/1500 Loss 0.58711\n",
            "Epoch 1090/1500 Loss 0.58661\n",
            "Epoch 1100/1500 Loss 0.58611\n",
            "Epoch 1110/1500 Loss 0.58562\n",
            "Epoch 1120/1500 Loss 0.58513\n",
            "Epoch 1130/1500 Loss 0.58465\n",
            "Epoch 1140/1500 Loss 0.58417\n",
            "Epoch 1150/1500 Loss 0.58369\n",
            "Epoch 1160/1500 Loss 0.58322\n",
            "Epoch 1170/1500 Loss 0.58276\n",
            "Epoch 1180/1500 Loss 0.58229\n",
            "Epoch 1190/1500 Loss 0.58184\n",
            "Epoch 1200/1500 Loss 0.58138\n",
            "Epoch 1210/1500 Loss 0.58093\n",
            "Epoch 1220/1500 Loss 0.58048\n",
            "Epoch 1230/1500 Loss 0.58004\n",
            "Epoch 1240/1500 Loss 0.57960\n",
            "Epoch 1250/1500 Loss 0.57916\n",
            "Epoch 1260/1500 Loss 0.57873\n",
            "Epoch 1270/1500 Loss 0.57830\n",
            "Epoch 1280/1500 Loss 0.57787\n",
            "Epoch 1290/1500 Loss 0.57745\n",
            "Epoch 1300/1500 Loss 0.57703\n",
            "Epoch 1310/1500 Loss 0.57661\n",
            "Epoch 1320/1500 Loss 0.57619\n",
            "Epoch 1330/1500 Loss 0.57578\n",
            "Epoch 1340/1500 Loss 0.57537\n",
            "Epoch 1350/1500 Loss 0.57496\n",
            "Epoch 1360/1500 Loss 0.57456\n",
            "Epoch 1370/1500 Loss 0.57416\n",
            "Epoch 1380/1500 Loss 0.57376\n",
            "Epoch 1390/1500 Loss 0.57336\n",
            "Epoch 1400/1500 Loss 0.57296\n",
            "Epoch 1410/1500 Loss 0.57257\n",
            "Epoch 1420/1500 Loss 0.57218\n",
            "Epoch 1430/1500 Loss 0.57179\n",
            "Epoch 1440/1500 Loss 0.57140\n",
            "Epoch 1450/1500 Loss 0.57102\n",
            "Epoch 1460/1500 Loss 0.57064\n",
            "Epoch 1470/1500 Loss 0.57026\n",
            "Epoch 1480/1500 Loss 0.56988\n",
            "Epoch 1490/1500 Loss 0.56950\n",
            "Epoch 1500/1500 Loss 0.56913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04992986411710541"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "D_in, H, D_out = 54, 100, 7\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ").to(\"cuda\")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n",
        "\n",
        "Y_t = torch.from_numpy((y_train - 1).astype(np.int64)).long().cuda()\n",
        "\n",
        "X_t = torch.from_numpy(X_train).float().cuda()\n",
        "\n",
        "epochs = 1500\n",
        "log_each = 10\n",
        "l = []\n",
        "model.train()\n",
        "for e in range(1, epochs+1):\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(X_t)\n",
        "\n",
        "    # loss\n",
        "    loss = criterion(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    # ponemos a cero los gradientes\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backprop (calculamos todos los gradientes automáticamente)\n",
        "    loss.backward()\n",
        "\n",
        "    # update de los pesos\n",
        "    optimizer.step()\n",
        "\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "ipyuFlAIm6xV"
      },
      "source": [
        "## Modelos custom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "_uh7djQTm6xV"
      },
      "source": [
        "Si bien en muchos casos definir una `red neuronal` como una secuencia de capas es suficiente, en otros casos será un factor limitante. Un ejemplo son las redes residuales, en las que no sólo utilizamos la salida de una capa para alimentar la siguiente si no que, además, le sumamos su propia entrada. Este tipo de arquitectura no puede ser definida con la clase `Sequential`, y para ello necesitamos hacer un modelo *customizado*. Para ello, `Pytroch` nos ofrece la siguiente sintaxis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:08.642713Z",
          "start_time": "2020-08-15T12:22:08.628592Z"
        },
        "hidden": true,
        "id": "zP6-77c5m6xW"
      },
      "outputs": [],
      "source": [
        "# creamos una clase que hereda de `torch.nn.Module`\n",
        "\n",
        "class ModeloPersonalizado(torch.nn.Module):\n",
        "\n",
        "    # constructor\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "\n",
        "        # llamamos al constructor de la clase madre\n",
        "        super(ModeloPersonalizado, self).__init__()\n",
        "\n",
        "        # definimos nuestras capas\n",
        "        self.fc1 = torch.nn.Linear(D_in, H)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(H, D_out)\n",
        "\n",
        "    # lógica para calcular las salidas de la red\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "2jwizXIgm6xW"
      },
      "source": [
        "En primer lugar, necesitamos definir una nueva clase que herede de la clase `torch.nn.Module`. Esta clase madre aportará toda la funcionalidad esencial que necesita una `red neuronal` (soporte GPU, iterar por sus parámeteros, etc). Luego, en esta clase necesitamos definir mínimos dos funciones:\n",
        "\n",
        "- `init`: en el constructor llamaremos al constructor de la clase madre y después definiremos todas las capas que querramos usar en la red.\n",
        "- `forward`: en esta función definimos toda la lógica que aplicaremos desde que recibimos los inputs hasta que devolvemos los outputs.\n",
        "\n",
        "En el ejemplo anterior simplemente hemos replicado la misma red (puedes conseguir el mismo efecto usando la clase `Sequential`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:08.658711Z",
          "start_time": "2020-08-15T12:22:08.644712Z"
        },
        "hidden": true,
        "id": "zhaXSvoVm6xW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36aaf38a-78b0-430f-f04a-4dfcc90a91f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.7781, -0.4585, -1.5557,  ..., -0.1267, -1.5205,  0.2482],\n",
            "        [ 0.6791, -1.3579, -0.2597,  ..., -0.6724, -0.5778, -1.3143],\n",
            "        [ 1.8858,  0.0670,  1.1524,  ..., -0.9702, -0.1827, -0.6335],\n",
            "        ...,\n",
            "        [-0.6763,  1.1758,  1.7239,  ..., -0.7012,  0.7725,  0.0133],\n",
            "        [ 0.5859,  2.0100,  0.9898,  ...,  0.9272, -1.9069,  0.7469],\n",
            "        [-0.4950, -0.2086,  0.2589,  ..., -0.2553,  1.1328,  0.0307]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model = ModeloPersonalizado(54, 100, 7)\n",
        "# Codigo para saber si el modelo esta votando los datos en las cantidades correctas\n",
        "x_prueba = torch.randn(500, 54)\n",
        "print(x_prueba)\n",
        "outputs = model(x_prueba)\n",
        "outputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "_RkPO5hum6xW"
      },
      "source": [
        "Ahora, podemos entrenar nuestra red de la misma forma que lo hemos hecho anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:09.941710Z",
          "start_time": "2020-08-15T12:22:08.659711Z"
        },
        "hidden": true,
        "id": "idh4YMn6m6xX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "905184e9-15a3-43d1-d6c1-2b6ac2e07274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 Loss 1.11708\n",
            "Epoch 20/100 Loss 0.97090\n",
            "Epoch 30/100 Loss 0.90646\n",
            "Epoch 40/100 Loss 0.86141\n",
            "Epoch 50/100 Loss 0.83152\n",
            "Epoch 60/100 Loss 0.80865\n",
            "Epoch 70/100 Loss 0.79048\n",
            "Epoch 80/100 Loss 0.77584\n",
            "Epoch 90/100 Loss 0.76367\n",
            "Epoch 100/100 Loss 0.75325\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07461941602196157"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model.to(\"cuda\")\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n",
        "\n",
        "X_t = torch.from_numpy(X_train).float().cuda()\n",
        "Y_t = torch.from_numpy((y_train - 1).astype(np.int64)).long().cuda()\n",
        "\n",
        "epochs = 100\n",
        "log_each = 10\n",
        "l = []\n",
        "model.train()\n",
        "for e in range(1, epochs+1):\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(X_t)\n",
        "\n",
        "    # loss\n",
        "    loss = criterion(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    # ponemos a cero los gradientes\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backprop (calculamos todos los gradientes automáticamente)\n",
        "    loss.backward()\n",
        "\n",
        "    # update de los pesos\n",
        "    optimizer.step()\n",
        "\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Rh3bxMrmm6xX"
      },
      "source": [
        "Aquí puedes ver otro ejemplo de como definir un `MLP` con conexiones residuales, algo que no podemos hacer simplemente usando un modelo secuencial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:09.956710Z",
          "start_time": "2020-08-15T12:22:09.942710Z"
        },
        "hidden": true,
        "id": "l-6qAZn1m6xX"
      },
      "outputs": [],
      "source": [
        "class ModelCustom2(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super(ModelCustom2, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(D_in, H)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(H, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.fc1(x)\n",
        "        x = self.relu(x1)\n",
        "        x = self.fc2(x + x1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:11.314772Z",
          "start_time": "2020-08-15T12:22:09.958712Z"
        },
        "hidden": true,
        "id": "EaSLokO7m6xX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a62289-bd26-42d0-942a-551f32b793bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 Loss 1.20897\n",
            "Epoch 20/100 Loss 0.99608\n",
            "Epoch 30/100 Loss 0.90713\n",
            "Epoch 40/100 Loss 0.85752\n",
            "Epoch 50/100 Loss 0.82543\n",
            "Epoch 60/100 Loss 0.80270\n",
            "Epoch 70/100 Loss 0.78559\n",
            "Epoch 80/100 Loss 0.77211\n",
            "Epoch 90/100 Loss 0.76113\n",
            "Epoch 100/100 Loss 0.75194\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1123034689293736"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model = ModelCustom2(54, 100, 7).to(\"cuda\")\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.2)\n",
        "\n",
        "X_t = torch.from_numpy(X_train).float().cuda()\n",
        "Y_t = torch.from_numpy((y_train - 1).astype(np.int64)).long().cuda()\n",
        "\n",
        "epochs = 100\n",
        "log_each = 10\n",
        "l = []\n",
        "model.train()\n",
        "for e in range(1, epochs+1):\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(X_t)\n",
        "\n",
        "    # loss\n",
        "    loss = criterion(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    # ponemos a cero los gradientes\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backprop (calculamos todos los gradientes automáticamente)\n",
        "    loss.backward()\n",
        "\n",
        "    # update de los pesos\n",
        "    optimizer.step()\n",
        "\n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "sgoJC4nIm6xY"
      },
      "source": [
        "De esta manera, tenemos mucha flexibilidad para definir nuestras redes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "s1ZrxJsJm6xY"
      },
      "source": [
        "## Accediendo a las capas de una red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "TC470LoYm6xY"
      },
      "source": [
        "En ocasiones queremos acceder a una capa en particular de nuestra red. Para ello, podemos acceder utilizando su nombre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:11.329809Z",
          "start_time": "2020-08-15T12:22:11.316772Z"
        },
        "hidden": true,
        "id": "K5VAtILVm6xY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26347694-69af-4f8e-afa3-5d25e48e1fe4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelCustom2(\n",
              "  (fc1): Linear(in_features=54, out_features=100, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=100, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:11.345809Z",
          "start_time": "2020-08-15T12:22:11.332809Z"
        },
        "hidden": true,
        "id": "_EfUdON5m6xY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb4b1af-2bd1-48ef-9f40-5e7c90c408ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=54, out_features=100, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.fc1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "5vXjUwhmm6xZ"
      },
      "source": [
        "También podemos acceder directamente a los tensores que contienen los parámetros con las propiedades adecuadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:11.360809Z",
          "start_time": "2020-08-15T12:22:11.346809Z"
        },
        "hidden": true,
        "id": "C6Wy_6cXm6xZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "945f6c3f-a3aa-407a-a263-7a9261886096"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0031,  0.0714,  0.0770,  ...,  0.0239, -0.0288, -0.0630],\n",
              "        [ 0.0244,  0.0344,  0.0729,  ..., -0.0571,  0.0500,  0.0279],\n",
              "        [-0.1135, -0.0349, -0.0513,  ..., -0.1303, -0.0727, -0.1166],\n",
              "        ...,\n",
              "        [-0.2517, -0.1013,  0.1205,  ..., -0.0147, -0.1496,  0.1100],\n",
              "        [-0.0465, -0.1048,  0.1291,  ...,  0.0529, -0.1210, -0.0795],\n",
              "        [ 0.1224, -0.0613,  0.1408,  ...,  0.0046, -0.0835,  0.0087]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.fc1.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:11.375809Z",
          "start_time": "2020-08-15T12:22:11.361809Z"
        },
        "hidden": true,
        "id": "5TbpHDGKm6xZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a5054c-692a-4be0-8c73-b8507b9a7517"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([ 5.0099e-02, -3.9974e-02,  5.8869e-02,  9.4687e-02,  1.8843e-02,\n",
              "        -4.0517e-02,  2.7967e-01,  6.3748e-02,  1.3238e-01,  9.1496e-02,\n",
              "         1.3607e-01,  4.7311e-02,  1.0187e-01, -8.4626e-02,  2.3545e-01,\n",
              "         1.6373e-01,  3.5412e-02, -1.0690e-01,  4.2924e-02, -7.6842e-02,\n",
              "         1.0524e-02,  7.0393e-02,  3.1519e-01,  1.0598e-01,  1.2837e-01,\n",
              "        -1.7713e-02,  5.5963e-02,  2.4937e-02,  9.8665e-02,  1.7711e-01,\n",
              "         5.4843e-02, -6.4687e-02,  8.3909e-02, -6.1571e-02, -7.9759e-02,\n",
              "         1.0703e-01,  1.2323e-01,  3.0121e-01,  1.2234e-01, -7.2656e-02,\n",
              "         6.2813e-02,  3.4614e-02,  1.8632e-01, -1.4641e-01, -6.1977e-02,\n",
              "        -3.9726e-03,  5.5159e-03,  8.5251e-02,  1.7911e-01,  2.4912e-02,\n",
              "        -1.1540e-02, -5.4404e-02, -2.5532e-02,  2.1383e-01,  1.1876e-01,\n",
              "         9.4801e-02,  2.0144e-01,  1.0957e-01,  1.4105e-03,  6.6497e-02,\n",
              "         4.7184e-02, -2.4171e-02, -9.5881e-03, -1.0617e-01, -5.9555e-02,\n",
              "        -1.7026e-01, -3.6401e-02, -1.0327e-01,  3.7159e-02,  6.4379e-02,\n",
              "         1.1996e-01,  9.2597e-02, -7.0619e-02,  1.6608e-01,  8.8057e-02,\n",
              "        -1.7333e-01, -5.1454e-02, -1.0924e-04,  3.1737e-02, -1.3256e-01,\n",
              "        -4.6316e-02, -3.5558e-02,  4.4146e-03,  3.6414e-02,  9.0557e-02,\n",
              "        -1.3515e-01, -1.6070e-01, -7.4121e-02,  1.1486e-01,  2.3988e-02,\n",
              "         1.1508e-01, -3.7279e-02,  4.1761e-01,  2.4673e-01,  3.4785e-02,\n",
              "         1.3850e-01,  2.7050e-01, -1.1321e-01, -7.5849e-02,  9.5956e-02],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "model.fc1.bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "oqraljgym6xZ"
      },
      "source": [
        "Es posible sobreescribir una capa de la siguiente manera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:11.391810Z",
          "start_time": "2020-08-15T12:22:11.376809Z"
        },
        "hidden": true,
        "id": "xIwyV17em6xZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820f16ba-2ab6-4b86-bb93-6c0648a9e704"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelCustom2(\n",
              "  (fc1): Linear(in_features=54, out_features=100, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.fc2 = torch.nn.Linear(100, 1)\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "eVLw3r9im6xZ"
      },
      "source": [
        "Ahora, la capa final de nuestra red tiene solo una salida. Esta nueva capa ha sido inicializada de manera aleatoria, por lo que esta nueva red no nos va a servir de mucho. Sin embargo, podríamos volver a entrenar esta red en otro problema en el que solo necesitemos una salida aprovechando los pesos que ya hemos entrenado anteriormente con el dataset MNIST. Esto es la base del *transfer learning*, una técnica que utilizaremos muchísimo más adelante y la cual explicaremos en detalle.\n",
        "\n",
        "A continuación encontrarás varios trucos a la hora de crear redes neuronales a partir de otras que te pueden resultar útiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:11.406809Z",
          "start_time": "2020-08-15T12:22:11.393812Z"
        },
        "hidden": true,
        "id": "JfE83wXtm6xZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e6a11c-6656-4a82-c3b3-8516e79518ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=54, out_features=100, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=100, out_features=1, bias=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# obtener una lista con las capas de una red\n",
        "\n",
        "list(model.children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:11.422810Z",
          "start_time": "2020-08-15T12:22:11.408810Z"
        },
        "hidden": true,
        "id": "wkaUklFHm6xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfb5acd-84fe-40dd-e895-43042dbd29d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=54, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# crear nueva red a partir de la lista (excluyendo las útlimas dos capa)\n",
        "\n",
        "new_model = torch.nn.Sequential(*list(model.children())[:-2])\n",
        "new_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-15T12:22:11.438809Z",
          "start_time": "2020-08-15T12:22:11.424811Z"
        },
        "hidden": true,
        "id": "AcGFOSU5m6xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce4793ee-0592-48a1-ee77-15322d228cd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Linear(in_features=54, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# crear nueva red a partir de la lista (excluyendo las útlima capa)\n",
        "\n",
        "new_model = torch.nn.ModuleList(list(model.children())[:-1])\n",
        "new_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IanjDRkm6xa"
      },
      "source": [
        "## Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwR1F8c9m6xa"
      },
      "source": [
        "En este post hemos visto la funcionalidad que `Pytorch` nos ofrece a la hora de definir y entrenar nuestras `redes neuronales`. El paquete `torch.nn` contiene todo lo necesario para diseñar nuestros modelos, ya sea de manera secuencial o con una clase *custom* para arquitecturas más complicadas. También nos da muchas funciones de pérdida que podemos usar directamente para entrenar las redes. Te recomiendo encarecidamente que le eches un vistazo a la [documentación](https://pytorch.org/docs/stable/nn.html) par hacerte una idea de todo lo que puedes hacer. También hemos visto como el paquete `torch.optim` nos oferece algoritmos de optimización que también nos hacen la vida más fácil a la hora de entrenar nuestras redes."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}